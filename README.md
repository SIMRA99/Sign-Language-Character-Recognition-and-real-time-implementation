# Sign-Language-Character-Recognition-and-real-time-implementation


The Sign Language Recognition with deep learning project aims to develop a system that can  recognize and translate sign language into text. This project employs a deep learning approach to  process and analyze the complex and dynamic patterns of sign language gestures.

The system uses a convolutional neural network (CNN), and implemented using MediaPipe and OpenCV.

The dataset used for this project is the “Sign Language MNIST”
.
The performance of the model is evaluated based on accuracy and precision, and the proposed system  aim to accurately recognize and translate sign language gestures into text.

The proposed system has the potential to improve the communication and accessibility for the deaf  and hard-of-hearing community
![image](https://user-images.githubusercontent.com/57862480/229497752-c7c1cd70-6796-4294-a5ec-deee1ec8a79f.png)




