{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05b4bfa2",
   "metadata": {},
   "source": [
    "#SIGN LANGUAGE CHARACTER RECOGNITION CODE \n",
    "#Sign language is the only mode of communication for the hard-of-hearing community and thus it becomes important to develop a system that can recognizr sign language to bridge the gap of communication. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedeffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as npy # linear algebra\n",
    "import pandas as pds # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for m_filename in filenames:\n",
    "        print(os.path.join(dirname, m_filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pds\n",
    "import numpy as npy\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9076d59",
   "metadata": {},
   "source": [
    "# Loading the ASL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd38a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sign Language MNIST” and is a public-domain free-to-use dataset with pixel information for around 1,000 images of each of 24 ASL Letters, excluding J and Z as they are gesture-based signs. Training data= (27,455 cases) and test data= (7172 cases)\n",
    "\n",
    "#The dataset is preprocessed by converting the raw sign language video data into a sequence of frames. Each frame is preprocessed to extract features using a convolutional neural network (CNN). CNN is designed to learn and extract relevant features from sign language character images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pds.read_csv (r\"C:\\Users\\simra\\Downloads\\TEAM ALPHA\\signmnisttrain\\signmnisttrain.csv\") \n",
    "test_df = pds.read_csv(r\"C:\\Users\\simra\\Downloads\\TEAM ALPHA\\sign_mnist_test\\sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pds.read_csv(r\"C:\\Users\\simra\\Downloads\\TEAM ALPHA\\sign_mnist_test\\sign_mnist_test.csv\")\n",
    "y = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa480be6",
   "metadata": {},
   "source": [
    "# Data Visualization and Preprocessing¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf63582",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10)) # Label Count\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "del train_df['label']\n",
    "del test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0475040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_b = LabelBinarizer()\n",
    "y_train = label_b.fit_transform(y_train)\n",
    "y_test = label_b.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce43f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7895f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data from 1-D to 3-D as required through input by CNN's\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2,5) \n",
    "f.set_size_inches(10, 10)\n",
    "k = 0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i,j].imshow(x_train[k].reshape(28, 28) , cmap = \"gray\")\n",
    "        k += 1\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e3e837",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92723b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation to prevent overfitting\n",
    "\n",
    "data_g = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "data_g.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee882f",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc689ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate_reduc = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 24 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(data_g.flow(x_train,y_train, batch_size = 128) ,epochs = 22 , validation_data = (x_test, y_test) , callbacks = [learning_rate_reduc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bc61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis after Model Training¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3eb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(20)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_accur = history.history['accuracy']\n",
    "train_lossess = history.history['loss']\n",
    "val_accur = history.history['val_accuracy']\n",
    "val_lossess = history.history['val_loss']\n",
    "fig.set_size_inches(16,9)\n",
    "\n",
    "ax[0].plot(epochs , train_accur , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_accur , 'ro-' , label = 'Testing Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_lossess , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_lossess , 'r-o' , label = 'Testing Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_made = model.predict(x_test)\n",
    "class_xx=npy.argmax(predictions_made, axis=1)\n",
    "for i in range(len(class_xx)):\n",
    "    if(class_xx[i] >= 9):\n",
    "        class_xx[i]+=1\n",
    "class_xx[:5]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c838b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_s = [\"Class \" + str(i) for i in range(25) if i != 9]\n",
    "print(classification_report(y, predictions_made, target_names = classes_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix  = confusion_matrix(y,predictions_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_sc = accuracy_score(y_test, predictions_made)\n",
    "print('Accuracy Score = ', accuracy_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_given = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I','K', 'L', 'M', \n",
    "               'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59295040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "vector = npy.vectorize(np.int_)\n",
    "i = random.randint(1,len(predictions_made))\n",
    "plt.imshow(x_test[i,:,:,0]) \n",
    "print(\"Predicted Label: \", class_names_given[int(predictions_made[i])])\n",
    "print(\"True Label: \", class_names_given[int(y_test[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e630f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix = pds.DataFrame(cmatrix , index = [i for i in range(25) if i != 9] , columns = [i for i in range(25) if i != 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eaa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(cmatrix,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = npy.nonzero(predictions_made == y)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
